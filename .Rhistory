barplot(bigdat$`Count(Site_ID)`, names.arg = bigdat$Country, ylab="# of sites",
cex.names = 0.75, cex.axis = 0.75)
dev.off()
sqlQuery(channel, "SHOW TABLES")
sqlQuery(channel, "DESCRIBE Tracking_log")
#Get info on queries
dat = sqlQuery(channel, "SELECT * FROM Tracking_log")
#Get info on queries
library(plyr)
?summarize
byScript = ddply(dat, "Script_Name", summarise)
byScript = ddply(dat, "Script_Name", summarise, n = count(ID))
byScript = ddply(dat, "Script_Name", summarise, n = nrow(dat))
?aggregate
byScript = aggregate(dat, dat$Script_Name, FUN = "count")
byScript = aggregate(dat, by = list(dat$Script_Name), FUN = "count")
summary(byScript)
byScript = ddply(dat, "Script_Name", summarise, n = nrow(dat))
byScript = ddply(dat, "Script_Name", summarise, n = length(ID))
as.Date(dat$Time[5])
dat$Date = as.Date(dat$Time)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate$cumN = rep(0, nrow(byDate))
byDate$cumN = byDate$n
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN = byDate$cumN[i-1] + byDate$n[i]}
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate$cumN = byDate$n
dat$Date = as.Date(dat$Time)
View(dat)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order(byDate$Date),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN = byDate$cumN[i-1] + byDate$n[i]}
plot(byDate$Date, byDate$cumN)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order(byDate$Date),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN[i] = byDate$cumN[i-1] + byDate$n[i]}
plot(byDate$Date, byDate$cumN)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries")
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = l)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l")
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lwt=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lw=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lw=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lwd=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
png("downloads.png", width=6, height=4, units="in", res=300)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
png("downloads.png", width=6, height=4, units="in", res=300)
par(mai = c(0.8,0.8,0.4,0.4))
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
par(mai = c(1,1,0.4,0.4))
png("downloads.png", width=6, height=4, units="in", res=300)
par(mai = c(1,1,0.4,0.4))
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
channel = odbcConnect("WIDB")
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELCT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
old.ids = smps$Sample_ID[10:14]
old.ids
old.ids = as.character(old.ids)
ids = data.frame(old.ids, "new.ids" = old.ids)
ids
ids$new.ids = paste0("18-192_", ids$new.ids)
ids
?proj4string
library(sp)
?proj4string
?projectRaster
library(raster)
?projectRaster
i=2
paste("UPDATE Samples SET Sample_ID =", ids$new.ids[i], "WHERE Sample_ID =", ids$old.ids[i])
paste("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'")
paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
channel = odbcConnect("WIDB")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
wi = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
wi$Sample_ID[1]
wi$Sample_ID[1] == smps$Sample_ID[1]
as.character(wi$Sample_ID[1]) == as.character(smps$Sample_ID[1])
View(smps)
View(tmp)
View(wi)
ids
old.ids = sqlQuery(channel, "SELECT Sample_ID FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
old.ids
ids$old.ids = old.ids
ids$new.ids[1] = "18-192_GJBMISC18-010"
ids$new.ids[2] = "18-192_GJBMISC18-011"
ids$new.ids[3] = "18-192_GJBMISC18-012"
ids$new.ids[4] = "18-192_GJBMISC18-013"
ids$new.ids[5] = "18-192_GJBMISC18-014"
ids
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$Sample_ID[i], "'"))
}
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
wi = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps$Sample_ID
wi$Sample_ID
ids
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$Sample_ID[i], "'")
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids, "'")
names(ids[,1]) = "old.ids"
ids
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids, "'")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
close(channel)
close(channel)
library(raster)
tst = matrix(,nrow = 500, ncol = 500)
for(i in 1:500){
for(j in 1:500){
tst[i,j] = 10 + 5 * sin(i/60) + (j/100) ^ 2
}
}
tst.r = raster(tst)
e = extent(0.1999,0.7999,0.1999,0.7999)
domain = extract(tst.r, extent)
pol = matrix(c(0.1999, 0.1999, 0.1999, 0.7999, 0.7999, 0.7999, 0.7999,
0.1999, 0.1999, 0.1999), ncol = 2, byrow = TRUE)
pol.pol = Polygon(pol)
pol.pols = Polygons(list(pol.pol), "domain")
pol.sp = SpatialPolygons(list(pol.pols))
domain = extract(tst.r, pol.sp)
sum(domain[[1]])
mean(domain[[1]])
tst = matrix(,nrow = 100, ncol = 100)
for(i in 1:100){
for(j in 1:100){
tst[i,j] = 10 + 5 * sin(i/15) + (j/10)
}
}
tst.r = raster(tst)
plot(tst.r)
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
v = rnorm(50)
mean(v)
sd(v)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig5 = vals + rnorm(50)*5
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth1.csv")
dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, dat)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth1.csv")
dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, dat)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
coords = dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, coords)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth.csv")
for(i in 1:10){
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals = vals + rnorm(50)*2
dat = cbind(dat, vals)
fn = paste0("C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth",i,".csv")
write.csv(dat, fn)
}
for(i in 1:10){
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals = vals + rnorm(50)*1.5
dat = cbind(dat, vals)
fn = paste0("C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth",i,".csv")
write.csv(dat, fn)
}
pol = matrix(c(0.2, 0.2, 0.2, 0.8, 0.8, 0.8, 0.8, 0.2, 0.2, 0.2), ncol = 2, byrow = TRUE)
pol.pol = Polygon(pol)
pol.pols = Polygons(list(pol.pol), "domain")
pol.sp = SpatialPolygons(list(pol.pols))
domain = extract(tst.r, pol.sp)
sum(domain[[1]])
mean(domain[[1]])
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT Site_ID FROM Sites WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = '' WHERE Country = ' '")
sqlQuery(channel, "SELECT Site_ID FROM Sites WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = '' WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = NULL WHERE Country = ' '")
install.packages(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("SPATIAL-Lab/isorig", force=TRUE)
?Bacon
library(rbacon)
?Bacon
?rbacon
library(devtools)
devtools::install_github("SPATIAL-Lab/isorig", force=T)
library(isOrigin)
d = subOrigData(taxon = "Homo sapiens")
plot(d$Latitude, d$d2H)
data("naMap")
data("d2H_world")
data("d2h_world")
d = subOrigData(taxon = "Homo sapiens", mask = naMap)
plot(d$Latitude, d$d2H)
d = d[d$Latitude < 50,]
plot(d$Latitude, d$d2H)
r = calRaster(d, d2h_world, mask = naMap)
getwd()
id = c("a", "b", "c", "d")
d2h = c(-110, -105, -90, -102)
dd = data.frame(id, d2h)
asn = pdRaster(r$isoscape.rescale$mean,r$isoscape.rescale$sd,unknown=dd,mask=naMap)
p1 <- c(-100,60,-100,65,-110,65,-110,60,-100,60)
p1 <- matrix(p1, 5,2, byrow = T)
p1 <- Polygon(p1)
p1 <- Polygons(list(p1), "p1")
p2 <- c(-100,40,-100,45,-110,45,-110,40,-100,40)
p2 <- matrix(p2, 5,2, byrow = T)
p2 <- Polygon(p2)
p2 <- Polygons(list(p2), "p2")
p12 <- SpatialPolygons(list(p1,p2),1:2)
lines(p12)
polygon(p12)
polygon(p1)
oddsRatio(asn, p12)
qtlRaster(asn, 0.75, thresholdType = 1)
qtlRaster(asn, 0.75, thresholdType = 2)
multRaster(asn)
unionP(asn)
ddd = multRaster(asn)
?SpatialPoints
pts = SpatialPoints(data.frame("Lat"=c(45,55),"Lon"=c(-80,-110)))
plot(pts)
ddd = multRaster(asn)
points(pts)
pts = SpatialPoints(data.frame("Lon"=c(-80,-110), "Lat"=c(45,55)))
points(pts)
oddsRatio(ddd,pts)
pts = data.frame("Lon"=c(-80,-110), "Lat"=c(45,55))
oddsRatio(ddd,pts)
devtools::install_github("SPATIAL-Lab/isorig", force=T)
oddsRatio(ddd,pts)
pts = SpatialPoints(data.frame("Lon"=c(-80,-110), "Lat"=c(45,55)))
oddsRatio(ddd,pts)
unionP(asn)
jointP
jointP(asn)
oddsRatio(asn, p12)
data(isOrigin)
library(isOrigin)
oddsRatio(asn, p12)
library(isOrigin)
data("naMap")
data("d2hworld")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
r = calRaster(dd, d2h_world, mask = naMap)
r = calRaster(d, d2h_world, mask = naMap)
id = c("A", "B", "C", "D")
v = c(-110, -120, -122, -100)
dd = data.frame(id, v)
asn = pdRaster(r, unknown = dd, mask = naMap)
pdRaster
summary(r)
asn = pdRaster(r$isoscape.rescale, unknown = dd, mask = naMap)
jointP(asn)
unionP(asn)
lons = c(-80, -110)
lats = c(40,55)
ll = matrix(c(lons, lats), nrow = 2, ncol = 2, byrow = FALSE)
ll
pts = SpatialPoints(ll)
points(pts)
oddsRatio(asn, pts)
s = oddsRatio(asn, pts)
summary(s)
s=jointP(asn)
qtlRaster(asn, 0.7, 2)
qtlRaster(asn, 0.7, 1)
d
dd
dd = data.frame(id=seq(1,100,1), v=rep(-100,100))
pdRaster(r$isoscape.rescale, dd, mask = naMap)
?pdRaster
pdRaster(r$isoscape.rescale, dd, mask = naMap, genplot = FALSE)
asn = pdRaster(r$isoscape.rescale, dd, mask = naMap, genplot = FALSE)
qtlRaster(asn, 0.7, 1)
unionP(asn)
1500 * 1.6^2
1500 / 1.6^2
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT * FROM Sites WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Latitude=45.475376 WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Longitude=13.616026 WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Site_Comments='coordinates updated 10/5/18, pers comm, P. Vreca' WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "SELECT * FROM Projects")
close(channel)
library("isOrigin", lib.loc="~/R/win-library/3.4")
remove.packages("isOrigin", lib="~/R/win-library/3.4")
devtools::install_github("SPATIAL-lab/isorig", force =T)
devtools::install_github("SPATIAL-lab/isorig", force =T)
devtools::install_github("SPATIAL-lab/isorig", force =T)
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
d = subOrigData(taxon = c("Homo sapiens"))
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
r = calRaster(known = d, isoscape = d2h_world, mask = naMap)
devtools::install_github("SPATIAL-lab/isorig", force =T)
data("naMap")
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
12500*1.525
nr = read.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv")
View(nr)
summary(nr)
types(nr)
type(nr)
sd = as.Date(nr$shipmentReceivedDate)
?as.Date
sd = as.Date(nr$shipmentReceivedDate, format = "%M/%D/%Y")
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%D/%Y")
sd
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%d/%Y")
nr$shipmentReceivedDate = sd
write.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv", row.names = FALSE)
###Now let's try to Shackelton site
d.i = read.table("Birner_2016/datasets/339-U1385_isotope_toRead.tab", sep = "\t", header = TRUE)
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/")
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
###Now let's try to Shackelton site
d.i = read.table("Birner_2016/datasets/339-U1385_isotope_toRead.tab", sep = "\t", header = TRUE)
d.e = read.table("Birner_2016/datasets/339-U1385_Mg-Ca_toRead.tab", sep = "\t", header = TRUE)
plot(d.e$Age..ka.BP., d.e$BWT..Ã‚.C.)
plot(d.i$Age..ka.BP., d.i$C..wuellerstorfi.d18O..per.mil.PDB.)
plot(d.e$Age..ka.BP., d.e$U..peregerina.Mg.Ca..mmol.mol.)
##Read in d18O calibration dataset
d_d18O_calib = read.xlsx("Marchitto/U_comp.xlsx", sheetIndex = 1)
d_d18O_calib = d_d18O_calib[d_d18O_calib$Ignore != 1,]
View(d_d18O_calib)
##Read in d18O calibration dataset
d_d18O_calib = read.csv("U_comp.csv")
d_d18O_calib = d_d18O_calib[d_d18O_calib$Ignore != 1,]
##Read in d18O calibration dataset
d_d18O_calib = read.csv("U_comp.csv")
d_d18O_calib = d_d18O_calib[is.na(d_d18O_calib$Ignore),]
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/")
set.seed(1197)
##Set up timeseries for d18O_sw and BWT modeling
ts.min = 18
ts.max = 0
ts.step = 0.05
ts.ages = seq(ts.min, ts.max, -ts.step)
ts.len = length(ts.ages)
##Prep the foram data, first read
d = read.csv("Lear_combined.csv")
##Now split out the d18O data and strip one outlier
d_o = d[!is.na(d$d18O),]
d_o = d_o[d_o$Sample.ID != "806B 47-5 38-43",]
#Timeseries index for each d18O sample
o_age.ind = round((ts.min - d_o$Age.Ma) / ts.step) + 1
##Now split out the MgCa data and get TS index
d_mgca = d[!is.na(d$MgCa),]
mgca_age.ind = round((ts.min - d_mgca$Age.Ma) / ts.step) + 1
##Read in paleo-seawater MgCa data
d_mgca_sw = read.csv("mgca_sw.txt")
##Set up timeseries for MgCa_sw modeling
mgca_ts.min = 110
mgca_ts.max = 0
mgca_ts.step = 1
mgca_ts.ages = seq(mgca_ts.min, mgca_ts.max, -mgca_ts.step)
mgca_ts.len = length(mgca_ts.ages)
##Age index for seawater MgCa samples
mgca_sw_age.ind = round((mgca_ts.min - d_mgca_sw$Age) / mgca_ts.step) + 1
##Add age seawater MgCa TS indicies for MgCa foram data
mgca_age.ind.sw = round((mgca_ts.min - d_mgca$Age.Ma) / mgca_ts.step) + 1
mgca_age.ind.all = matrix(c(mgca_age.ind, mgca_age.ind.sw), ncol = 2)
##Read in MgCa calibration dataset
d_mgca_calib = read.csv("mgca_calib.csv")
##Age index for MgCa calibration samples
mgca_calib_age.ind = round((mgca_ts.min - d_mgca_calib$Age) / mgca_ts.step) + 1
##Read in d18O calibration dataset
d_d18O_calib = read.csv("U_comp.csv")
d_d18O_calib = d_d18O_calib[is.na(d_d18O_calib$Ignore),]
##Parameters to be saved
parameters = c("d18O_sw", "BWT", "BWT.eps.ac", "BWT.var", "lc",
"d18O_sw.eps.ac", "d18O_sw.var", "MgCa_calib.var",
"MgCa_sw_m", "MgCa_sw_m.var", "MgCa_sw_m.eps.ac")
##Data to pass to BUGS model
dat = list(nages = ts.len, nmgca.ages = mgca_ts.len,
MgCa_calib.bwt.m = d_mgca_calib$BWT, MgCa_calib.bwt.sd = d_mgca_calib$BWT_sd, MgCa_calib = d_mgca_calib$MgCa,
d18O_calib.bwt.m = d_d18O_calib$Temperature_C, d18O_calib.bwt.sd = rep(0.2,nrow(d_d18O_calib)), d18O_calib = d_d18O_calib$U.SW_d18O,
MgCa_sw.age.ind = mgca_sw_age.ind, MgCa_sw = d_mgca_sw$MgCa, MgCa_sw.sd = d_mgca_sw$Sigma,
MgCa.age.ind = mgca_age.ind.all, MgCa = d_mgca$MgCa,
d18O.age.ind = o_age.ind, d18O = d_o$d18O)
##Here's the BUGS code
source("split_temporal.R")
##Run the inversion
t1 = proc.time()
post2 = jags(model.file = textConnection(split_AR), parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = 5000,
n.burnin = 1000, n.thin = 25)
proc.time() - t1
plot(-10, 0, xlab="Age", ylab ="Temperature", xlim=c(0,18), ylim=c(-3,11))
for(i in seq(1, sims, by = max(floor(sims / 5000),1))){
lines(ts.ages, post2$BUGSoutput$sims.list$BWT[i,], col = rgb(0,0,0, 0.01))
}
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 5], col="red")
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 3], col="red", lty=3)
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 7], col="red", lty=3)
points(d_mgca$Age.Ma, rep(-3, nrow(d_mgca)), pch=21, bg = "white")
sims = nrow(post2$BUGSoutput$sims.list$BWT)
BWT.start = match("BWT[1]", row.names(post2$BUGSoutput$summary))
d18O.start = match("d18O_sw[1]", row.names(post2$BUGSoutput$summary))
MgCa.start = match("MgCa_sw_m[1]", row.names(post2$BUGSoutput$summary))
plot(-10, 0, xlab="Age", ylab ="Temperature", xlim=c(0,18), ylim=c(-3,11))
for(i in seq(1, sims, by = max(floor(sims / 5000),1))){
lines(ts.ages, post2$BUGSoutput$sims.list$BWT[i,], col = rgb(0,0,0, 0.01))
}
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 5], col="red")
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 3], col="red", lty=3)
lines(ts.ages, post2$BUGSoutput$summary[BWT.start:ts.len, 7], col="red", lty=3)
points(d_mgca$Age.Ma, rep(-3, nrow(d_mgca)), pch=21, bg = "white")
plot(-10, 0, xlab="Age", ylab ="Seawater d18O", xlim=c(0,18), ylim=c(-1.5,2))
for(i in seq(1, sims, by = max(floor(sims / 5000),1))){
lines(ts.ages, post2$BUGSoutput$sims.list$d18O_sw[i,], col = rgb(0,0,0, 0.01))
}
lines(ts.ages, post2$BUGSoutput$summary[d18O.start:(d18O.start+ts.len-1), 5], col="red")
lines(ts.ages, post2$BUGSoutput$summary[d18O.start:(d18O.start+ts.len-1), 3], col="red", lty=3)
lines(ts.ages, post2$BUGSoutput$summary[d18O.start:(d18O.start+ts.len-1), 7], col="red", lty=3)
points(d_o$Age.Ma, rep(-1.5, nrow(d_o)), pch=21, bg = "white")
