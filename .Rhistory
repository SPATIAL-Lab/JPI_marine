par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
bigdat = dat[c(4:19),]
bigdat$Contact_Name = as.character(bigdat$Contact_Name)
bigdat$Contact_Name[1] = "IAEA"
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
bigdat = dat[c(4:19),]
bigdat$Contact_Name = as.character(bigdat$Contact_Name)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
bigdat = dat[c(5:15),]
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
bigdat = dat[c(5:20),]
bigdat$Contact_Name = as.character(bigdat$Contact_Name)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
dat = sqlQuery(channel, "SELECT Projects.Contact_Name, Count(Samples.Sample_ID) FROM
Projects INNER JOIN Samples ON Projects.Project_ID = Samples.Project_ID
WHERE Projects.Proprietary = 0 GROUP BY Projects.Contact_Name")
dat = dat[order(dat$`Count(Samples.Sample_ID)`, decreasing = TRUE),]
bigdat = dat[c(1:15),]
bigdat$Contact_Name = as.character(bigdat$Contact_Name)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
bigdat = dat[c(2:16),]
bigdat$Contact_Name = as.character(bigdat$Contact_Name)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
#bigdat$Contact_Name[1] = "IAEA"
png(filename = "nameshist.png", width = 7, height = 4, units = "in", res = 300)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, mgp=c(4,1,0))
dev.off()
#bigdat$Contact_Name[1] = "IAEA"
png(filename = "nameshist.png", width = 7, height = 4, units = "in", res = 300)
par(mai = c(2.0,1.2,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, cex.names = 0.75, cex.axis = 0.75, mgp=c(4,1,0))
dev.off()
#bigdat$Contact_Name[1] = "IAEA"
png(filename = "nameshist.png", width = 7, height = 4, units = "in", res = 300)
par(mai = c(1.5,1.0,0.4,0.4))
barplot(bigdat$`Count(Samples.Sample_ID)`, names.arg = bigdat$Contact_Name,
ylab = "# of samples", las=2, cex.names = 0.75, cex.axis = 0.75)
dev.off()
dat = sqlQuery(channel, "SELECT Country, Count(Site_ID) FROM Sites GROUP BY Country")
dat = dat[order(dat$`Count(Site_ID)`, decreasing = TRUE),]
bigdat = dat[c(1,3:16),]
par(mai = c(0.8,0.8, 0.4, 0.4))
barplot(bigdat$`Count(Site_ID)`, names.arg = bigdat$Country, ylab="# of sites",
cex.names = 0.75, cex.axis = 0.75)
dev.off()
png(filename = "bighist.png", width = 7, height = 4, units="in", res=300)
par(mai = c(0.8,0.8, 0.4, 0.4))
barplot(bigdat$`Count(Site_ID)`, names.arg = bigdat$Country, ylab="# of sites",
cex.names = 0.75, cex.axis = 0.75)
dev.off()
png(filename = "bighist.png", width = 7, height = 4, units="in", res=300)
par(mai = c(0.8,1.0, 0.4, 0.4))
barplot(bigdat$`Count(Site_ID)`, names.arg = bigdat$Country, ylab="# of sites",
cex.names = 0.75, cex.axis = 0.75)
dev.off()
sqlQuery(channel, "SHOW TABLES")
sqlQuery(channel, "DESCRIBE Tracking_log")
#Get info on queries
dat = sqlQuery(channel, "SELECT * FROM Tracking_log")
#Get info on queries
library(plyr)
?summarize
byScript = ddply(dat, "Script_Name", summarise)
byScript = ddply(dat, "Script_Name", summarise, n = count(ID))
byScript = ddply(dat, "Script_Name", summarise, n = nrow(dat))
?aggregate
byScript = aggregate(dat, dat$Script_Name, FUN = "count")
byScript = aggregate(dat, by = list(dat$Script_Name), FUN = "count")
summary(byScript)
byScript = ddply(dat, "Script_Name", summarise, n = nrow(dat))
byScript = ddply(dat, "Script_Name", summarise, n = length(ID))
as.Date(dat$Time[5])
dat$Date = as.Date(dat$Time)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate$cumN = rep(0, nrow(byDate))
byDate$cumN = byDate$n
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN = byDate$cumN[i-1] + byDate$n[i]}
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate$cumN = byDate$n
dat$Date = as.Date(dat$Time)
View(dat)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order("Date"),]
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order(byDate$Date),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN = byDate$cumN[i-1] + byDate$n[i]}
plot(byDate$Date, byDate$cumN)
byDate = ddply(dat, "Date", summarise, n = length(ID))
byDate = byDate[order(byDate$Date),]
byDate$cumN = byDate$n
for(i in 2:nrow(byDate)){byDate$cumN[i] = byDate$cumN[i-1] + byDate$n[i]}
plot(byDate$Date, byDate$cumN)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries")
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = l)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l")
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lwt=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lw=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lw=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Queries", type = "l", lwd=2)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
png("downloads.png", width=6, height=4, units="in", res=300)
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
png("downloads.png", width=6, height=4, units="in", res=300)
par(mai = c(0.8,0.8,0.4,0.4))
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
par(mai = c(1,1,0.4,0.4))
png("downloads.png", width=6, height=4, units="in", res=300)
par(mai = c(1,1,0.4,0.4))
plot(byDate$Date, byDate$cumN, xlab = "Date", ylab = "Cumulative Downloads", type = "l", lwd=2)
dev.off()
channel = odbcConnect("WIDB")
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELCT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE 'GJBMISC18%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE 'GJBMISC18%'")
old.ids = smps$Sample_ID[10:14]
old.ids
old.ids = as.character(old.ids)
ids = data.frame(old.ids, "new.ids" = old.ids)
ids
ids$new.ids = paste0("18-192_", ids$new.ids)
ids
?proj4string
library(sp)
?proj4string
?projectRaster
library(raster)
?projectRaster
i=2
paste("UPDATE Samples SET Sample_ID =", ids$new.ids[i], "WHERE Sample_ID =", ids$old.ids[i])
paste("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'")
paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
channel = odbcConnect("WIDB")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Samples SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
wi = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
wi$Sample_ID[1]
wi$Sample_ID[1] == smps$Sample_ID[1]
as.character(wi$Sample_ID[1]) == as.character(smps$Sample_ID[1])
View(smps)
View(tmp)
View(wi)
ids
old.ids = sqlQuery(channel, "SELECT Sample_ID FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
old.ids
ids$old.ids = old.ids
ids$new.ids[1] = "18-192_GJBMISC18-010"
ids$new.ids[2] = "18-192_GJBMISC18-011"
ids$new.ids[3] = "18-192_GJBMISC18-012"
ids$new.ids[4] = "18-192_GJBMISC18-013"
ids$new.ids[5] = "18-192_GJBMISC18-014"
ids
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$Sample_ID[i], "'"))
}
smps = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '18-192%'")
wi = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '18-192%'")
smps$Sample_ID
wi$Sample_ID
ids
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$Sample_ID[i], "'")
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids, "'")
names(ids[,1]) = "old.ids"
ids
paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids, "'")
for(i in 1:5){
sqlQuery(channel, paste0("UPDATE Water_Isotope_Data SET Sample_ID ='", ids$new.ids[i], "' WHERE Sample_ID ='", ids$old.ids[i], "'"))
}
close(channel)
close(channel)
library(raster)
tst = matrix(,nrow = 500, ncol = 500)
for(i in 1:500){
for(j in 1:500){
tst[i,j] = 10 + 5 * sin(i/60) + (j/100) ^ 2
}
}
tst.r = raster(tst)
e = extent(0.1999,0.7999,0.1999,0.7999)
domain = extract(tst.r, extent)
pol = matrix(c(0.1999, 0.1999, 0.1999, 0.7999, 0.7999, 0.7999, 0.7999,
0.1999, 0.1999, 0.1999), ncol = 2, byrow = TRUE)
pol.pol = Polygon(pol)
pol.pols = Polygons(list(pol.pol), "domain")
pol.sp = SpatialPolygons(list(pol.pols))
domain = extract(tst.r, pol.sp)
sum(domain[[1]])
mean(domain[[1]])
tst = matrix(,nrow = 100, ncol = 100)
for(i in 1:100){
for(j in 1:100){
tst[i,j] = 10 + 5 * sin(i/15) + (j/10)
}
}
tst.r = raster(tst)
plot(tst.r)
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
v = rnorm(50)
mean(v)
sd(v)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig5 = vals + rnorm(50)*5
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth1.csv")
dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, dat)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth1.csv")
dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, dat)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
coords = dat = data.frame("x" = xs, "y" = ys)
for(i in 1:10){
vals = extract(tst.r, coords)
vals = vals + rnorm(50)
dat = cbind(dat, vals)
}
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth2.csv")
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals.sig1 = vals + rnorm(50)
vals.sig3 = vals + rnorm(50)*3
dat = cbind(dat, vals, vals.sig1, vals.sig5)
write.csv(dat, "C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth.csv")
for(i in 1:10){
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals = vals + rnorm(50)*2
dat = cbind(dat, vals)
fn = paste0("C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth",i,".csv")
write.csv(dat, fn)
}
for(i in 1:10){
xs = runif(50)
ys = runif(50)
dat = data.frame("x" = xs, "y" = ys)
vals = extract(tst.r, dat)
vals = vals + rnorm(50)*1.5
dat = cbind(dat, vals)
fn = paste0("C:/Users/gjbowen/Dropbox/HypoMirror/Chao_RBK/synth",i,".csv")
write.csv(dat, fn)
}
pol = matrix(c(0.2, 0.2, 0.2, 0.8, 0.8, 0.8, 0.8, 0.2, 0.2, 0.2), ncol = 2, byrow = TRUE)
pol.pol = Polygon(pol)
pol.pols = Polygons(list(pol.pol), "domain")
pol.sp = SpatialPolygons(list(pol.pols))
domain = extract(tst.r, pol.sp)
sum(domain[[1]])
mean(domain[[1]])
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT Site_ID FROM Sites WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = '' WHERE Country = ' '")
sqlQuery(channel, "SELECT Site_ID FROM Sites WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = '' WHERE Country = ' '")
sqlQuery(channel, "UPDATE Sites SET Country = NULL WHERE Country = ' '")
install.packages(devtools)
install.packages("devtools")
library(devtools)
devtools::install_github("SPATIAL-Lab/isorig", force=TRUE)
?Bacon
library(rbacon)
?Bacon
?rbacon
library(devtools)
devtools::install_github("SPATIAL-Lab/isorig", force=T)
library(isOrigin)
d = subOrigData(taxon = "Homo sapiens")
plot(d$Latitude, d$d2H)
data("naMap")
data("d2H_world")
data("d2h_world")
d = subOrigData(taxon = "Homo sapiens", mask = naMap)
plot(d$Latitude, d$d2H)
d = d[d$Latitude < 50,]
plot(d$Latitude, d$d2H)
r = calRaster(d, d2h_world, mask = naMap)
getwd()
id = c("a", "b", "c", "d")
d2h = c(-110, -105, -90, -102)
dd = data.frame(id, d2h)
asn = pdRaster(r$isoscape.rescale$mean,r$isoscape.rescale$sd,unknown=dd,mask=naMap)
p1 <- c(-100,60,-100,65,-110,65,-110,60,-100,60)
p1 <- matrix(p1, 5,2, byrow = T)
p1 <- Polygon(p1)
p1 <- Polygons(list(p1), "p1")
p2 <- c(-100,40,-100,45,-110,45,-110,40,-100,40)
p2 <- matrix(p2, 5,2, byrow = T)
p2 <- Polygon(p2)
p2 <- Polygons(list(p2), "p2")
p12 <- SpatialPolygons(list(p1,p2),1:2)
lines(p12)
polygon(p12)
polygon(p1)
oddsRatio(asn, p12)
qtlRaster(asn, 0.75, thresholdType = 1)
qtlRaster(asn, 0.75, thresholdType = 2)
multRaster(asn)
unionP(asn)
ddd = multRaster(asn)
?SpatialPoints
pts = SpatialPoints(data.frame("Lat"=c(45,55),"Lon"=c(-80,-110)))
plot(pts)
ddd = multRaster(asn)
points(pts)
pts = SpatialPoints(data.frame("Lon"=c(-80,-110), "Lat"=c(45,55)))
points(pts)
oddsRatio(ddd,pts)
pts = data.frame("Lon"=c(-80,-110), "Lat"=c(45,55))
oddsRatio(ddd,pts)
devtools::install_github("SPATIAL-Lab/isorig", force=T)
oddsRatio(ddd,pts)
pts = SpatialPoints(data.frame("Lon"=c(-80,-110), "Lat"=c(45,55)))
oddsRatio(ddd,pts)
unionP(asn)
jointP
jointP(asn)
oddsRatio(asn, p12)
data(isOrigin)
library(isOrigin)
oddsRatio(asn, p12)
library(isOrigin)
data("naMap")
data("d2hworld")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
r = calRaster(dd, d2h_world, mask = naMap)
r = calRaster(d, d2h_world, mask = naMap)
id = c("A", "B", "C", "D")
v = c(-110, -120, -122, -100)
dd = data.frame(id, v)
asn = pdRaster(r, unknown = dd, mask = naMap)
pdRaster
summary(r)
asn = pdRaster(r$isoscape.rescale, unknown = dd, mask = naMap)
jointP(asn)
unionP(asn)
lons = c(-80, -110)
lats = c(40,55)
ll = matrix(c(lons, lats), nrow = 2, ncol = 2, byrow = FALSE)
ll
pts = SpatialPoints(ll)
points(pts)
oddsRatio(asn, pts)
s = oddsRatio(asn, pts)
summary(s)
s=jointP(asn)
qtlRaster(asn, 0.7, 2)
qtlRaster(asn, 0.7, 1)
d
dd
dd = data.frame(id=seq(1,100,1), v=rep(-100,100))
pdRaster(r$isoscape.rescale, dd, mask = naMap)
?pdRaster
pdRaster(r$isoscape.rescale, dd, mask = naMap, genplot = FALSE)
asn = pdRaster(r$isoscape.rescale, dd, mask = naMap, genplot = FALSE)
qtlRaster(asn, 0.7, 1)
unionP(asn)
1500 * 1.6^2
1500 / 1.6^2
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT * FROM Sites WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Latitude=45.475376 WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Longitude=13.616026 WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "UPDATE Sites SET Site_Comments='coordinates updated 10/5/18, pers comm, P. Vreca' WHERE Site_Name = 'PORTOROZ'")
sqlQuery(channel, "SELECT * FROM Projects")
close(channel)
library("isOrigin", lib.loc="~/R/win-library/3.4")
remove.packages("isOrigin", lib="~/R/win-library/3.4")
devtools::install_github("SPATIAL-lab/isorig", force =T)
devtools::install_github("SPATIAL-lab/isorig", force =T)
devtools::install_github("SPATIAL-lab/isorig", force =T)
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
d = subOrigData(taxon = c("Homo sapiens"))
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
r = calRaster(known = d, isoscape = d2h_world, mask = naMap)
devtools::install_github("SPATIAL-lab/isorig", force =T)
data("naMap")
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
12500*1.525
nr = read.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv")
View(nr)
summary(nr)
types(nr)
type(nr)
sd = as.Date(nr$shipmentReceivedDate)
?as.Date
sd = as.Date(nr$shipmentReceivedDate, format = "%M/%D/%Y")
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%D/%Y")
sd
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%d/%Y")
nr$shipmentReceivedDate = sd
write.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv", row.names = FALSE)
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
?jags
jags
?adapt
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/u0133977/Dropbox/HypoMirror/JPI_marine/")
setwd("C:/Users/u0133977/Dropbox/HypoMirror/JPI_marine/")
plot(-11.8, -105, xlim = c(-20,-10), ylim=c(-180,-100))
abline(8,10)
abline(10.8)
abline(10,8)
plot(-11.8, -105, xlim = c(-20,-11), ylim=c(-160,-100))
abline(10,8)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21, bg="black")
plot(-11.8, -105, xlim = c(-18,-11), ylim=c(-140,-100))
abline(10,8)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21, bg="black")
lines(c(-11.8, -18.8), c(-105, -105-4.5*7))
#These data are from the authors' SI and include raw proxy measurements
de = read.csv("elderfield_2012_interp.csv")
##My local working directories
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/code/")
#Get and recalibrate original interpreted records using our MgCa slope (0.068)
#These data are directly from the authors' SI and include both raw measurements
#and their values interpreted using the Elderfield et al (2010) down-core calibration
#Only levels w/ both Mg/Ca and d18O data have been retained
db = read.csv("birner_2016_interp.csv")
View(db)
#These data are from the authors' SI and include raw proxy measurements
#Only levels w/ both Mg/Ca and d18O data have been retained
de = read.csv("elderfield_2012_interp.csv")
View(de)
?ecdf
?quantile
load("post_lear.RData")
mgca_sw_m.neo = mean(post.lear$BUGSoutput$sims.list$MgCa_sw_m[,80])
