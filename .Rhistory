data("naMap")
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
12500*1.525
nr = read.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv")
View(nr)
summary(nr)
types(nr)
type(nr)
sd = as.Date(nr$shipmentReceivedDate)
?as.Date
sd = as.Date(nr$shipmentReceivedDate, format = "%M/%D/%Y")
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%D/%Y")
sd
sd = as.Date(nr$shipmentReceivedDate, format = "%m/%d/%Y")
nr$shipmentReceivedDate = sd
write.csv("C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069B.csv")
write.csv(nr, "C:/Users/gjbowen/Desktop/receipt_form_D1820181008100705069.csv", row.names = FALSE)
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
?jags
jags
?adapt
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/u0133977/Dropbox/HypoMirror/JPI_marine/")
setwd("C:/Users/u0133977/Dropbox/HypoMirror/JPI_marine/")
plot(-11.8, -105, xlim = c(-20,-10), ylim=c(-180,-100))
abline(8,10)
abline(10.8)
abline(10,8)
plot(-11.8, -105, xlim = c(-20,-11), ylim=c(-160,-100))
abline(10,8)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21, bg="black")
plot(-11.8, -105, xlim = c(-18,-11), ylim=c(-140,-100))
abline(10,8)
points(c(-15.5, -17.2), c(-15.5*8+10, -17.2*8+10), pch=21, bg="black")
lines(c(-11.8, -18.8), c(-105, -105-4.5*7))
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT * FROM Projects WHERE Project_ID = '00164'")
sqlQuery(channel, "UPDATE Projects SET Proprietary = 0 WHERE Project_ID = '00164'")
sqlQuery(channel, "SELECT * FROM Projects WHERE Project_ID = '00164'")
sqrt(1000)
0.4*30
library(RODBC)
channel = odbcConnect("WIDB")
qrys = sqlQuery(channel, "SELECT MONTH(Time), COUNT(ID) FROM Tracking_log GROUP BY MONTH(Time)")
qrys = sqlQuery(channel, "SELECT MONTH(Time), YEAR(Time), COUNT(ID) FROM Tracking_log GROUP BY MONTH(Time) AND YEAR(Time)")
qrys = sqlQuery(channel, "SELECT MONTH(Time), YEAR(Time), COUNT(ID) FROM Tracking_log GROUP BY MONTH(Time), YEAR(Time)")
View(qrys)
qrys = qrys[qrys$`YEAR(Time)` = 2018,]
qrys = qrys[qrys$`YEAR(Time)` == 2018,]
qrys$Month = c("Jan18", "Feb18", "Mar18", "Apr18", "May18", "Jun18", "Jul18", "Aug18", "Sep18", "Oct18", "Nov18", "Dec18")
mean(qrys$`COUNT(ID)`)
library(RODBC)
odc = odbcConnect("ITCE")
sqlQuery(odc, "DESCRIBE Applications")
sqlQuery(odc, "SHOW TABLES")
sqlQuery(odc, "DESCRIBE application")
students = sqlQuery(odc, "SELECT * FROM application WHERE CYear = '2018'")
applied = sqlQuery(odc, "SELECT *.people,  *.application
FROM application INNER JOIN people ON
Person_ID.people =  Person_ID.application
WHERE CYear.application = '2018'")
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2018'")
View(applied)
enrl = sqlQuery(odc, "SELECT Enrolled FROM application")
sqlQuery(odc, "UPDATE application SET Enrolled = 'Yes' WHERE Enrolled = 'Yes '")
enrl = c("Yes", "", "Yes", "Yes", "Yes", "", "Yes", "Yes", "", "Yes", "Yes", "Yes", "", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "", "Yes", "", "Yes", "Yes", "", "Yes")
enrl.df = data.frame(applied$Person_ID, enrl)
enrl.df$enrl = as.character(enrl.df$enrl)
for(i in 1:nrow(enrl.df)){
sqlQuery(odc, paste0("UPDATE application SET Enrolled = '", enrl.df$enrl[i], "' WHERE
Person_ID = '", enrl.df$Person_ID, "'"))
}
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2018'")
i=1
paste0("UPDATE application SET Enrolled = '", enrl.df$enrl[i], "' WHERE
Person_ID = '", enrl.df$Person_ID[i], "'")
paste0("UPDATE application SET Enrolled = '", enrl.df$enrl[i], "' WHERE
Person_ID = '", enrl.df$applied.Person_ID[i], "'")
for(i in 1:nrow(enrl.df)){
sqlQuery(odc, paste0("UPDATE application SET Enrolled = '", enrl.df$enrl[i], "' WHERE
Person_ID = '", enrl.df$applied.Person_ID[i], "'"))
}
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2018'")
enrolled = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2018'
AND application.Enrolled = 'Yes'")
View(enrolled)
15/21
10/21
close(odc)
odc = odbcConnect("WIDB")
sqlQuery(odc, "SHOW TABLES")
sqlQuery(odc, "DESCRIBE Tracking_log")
sqlQuery(odc, "SELECT * FROM Tracking_log")
dat = sqlQuery(odc, "SELECT * FROM Tracking_log")
data = dat[dat$Time > '02/01/2018']
data = dat[dat$Time > '02/01/2018',]
View(dat)
data = dat[dat$Time > '2018-02-01',]
data = dat[dat$Time < '2018-09-30',]
sqlQuery(odc, "SELECT COUNT(Sample_ID) FROM Water_Isotope_Data")
sqlQuery(odc, "SELECT COUNT(Sample_ID) FROM Water_Isotope_Data")
odc = odbcConnect("WIDB")
sqlQuery(odc, "SELECT COUNT(Sample_ID) FROM Water_Isotope_Data")
close(odc)
odc = odbcConnect("ITCE")
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2018'")
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2019'")
View(applied)
View(applied)
write.csv(applied, "C:/Users/gjbowen/Desktop/applied.csv")
170*0.7
h = 120/18
h*2
h = h*2
h * 0.0002
h = h * 0.0002
h*16
28*8
=224/2
224/2
112/18
h = 112/18
h = h*2
h
h = h * 0.0002
h
h*1000
library(devtools)
install_github("SPATIAL-LAB/isorig")
install.packages("raster")
install.packages("raster")
install.packages("raster")
detach(raster, unload = TRUE)
detach("package:raster", unload = TRUE)
detach("package:sp", unload = TRUE)
library("abind", lib.loc="~/R/win-library/3.4")
detach("package:abind", unload=TRUE)
update.packages()
install.packages("backports")
library(devtools)
install_github("SPATIAL-LAB/isorig")
devtools::install_github(“SPATIAL-Lab/isorig”, force=T)
install_github(“SPATIAL-Lab/isorig”, force=T)
install_github("SPATIAL-LAB/isorig", force=TRUE)
detach("package:raster", unload=TRUE)
remove.packages("raster")
install.packages("raster")
install.packages("raster")
library(devtools)
install_github("SPATIAL-LAB/isorig", force = TRUE)
library(isOrigin)
?isOrigin
subOrigData
600/96
library(RODBC)
channel = odbcConnect("WIDB")
allus = sqlQuery(channel, "SELECT COUNT(Samples.Sample_ID) FROM Samples INNER JOIN Sites ON Samples.Site_ID = Sites.Site_ID WHERE Sites.Country = 'US'")
allus
gwus = sqlQuery(channel, "SELECT COUNT(Samples.Sample_ID) FROM Samples INNER JOIN Sites ON Samples.Site_ID = Sites.Site_ID WHERE Sites.Country = 'US' AND Samples.Project_ID = '00210'")
allgwus = sqlQuery(channel, "SELECT COUNT(Samples.Sample_ID) FROM Samples INNER JOIN Sites ON Samples.Site_ID = Sites.Site_ID WHERE Sites.Country = 'US' AND Samples.Type = 'Ground'")
gwus / allgwus
allgwus = sqlQuery(channel, "SELECT COUNT(Samples.Sample_ID) FROM Samples INNER JOIN Sites ON Samples.Site_ID = Sites.Site_ID WHERE Sites.Country = 'US' AND (Samples.Type = 'Ground' OR Samples.Type = 'Spring')")
gwus / allgwus
gwus / allus
allworld = sqlQuery(channel, "SELECT COUNT(Samples.Sample_ID) FROM Samples")
allworld
gwus / allworld
?isOrigin
library(isOrigin)
?isOrigin
libra
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "DESCRIBE People")
sqlQuery(channel, "SHOW TABLES")
close(channel)
channel = odbcConnect("ITCE")
sqlQuery(channel, "DESCRIBE People")
sqlQuery(channel, "SHOW TABLES")
sqlQuery(channel, "DESCRIBE people")
sqlQuery(channel, "SELECT * FROM people WHERE Last_Name = 'Bowen'")
sqlQuery(channel, "UPDATE People INSERT UNID='u6024188', First_Name='Alexis', Last_Name='Sims', Institution_Name='UU', Email='alexi.sims@utah.edu', Reviewer='both'")
sqlQuery(channel, "INSERT INTO people(UNID,First_Name,Last_Name,Institution_Name,Email,Reviewer) VALUES('u6024188','Alexis','Sims','UU','alexis.sims@utah.edu','both')")
sqlQuery(channel, "SELECT * FROM people WHERE Last_Name = 'Sims'")
sqlQuery(channel, "UPDATE people SET Student_Or_Instructor = 'i' WHERE Last_Name = 'Sims'")
library(RODBC)
channel = odbcConnect("WIDB")
dat = sqlQuery(channel, "SELECT * FROM Samples_test")
View(dat)
sqlQuery(channel, "DESCRIBE Projects")
pl = sqlQuery(channel, "SELECT Project_ID FROM Projects")
pl
sqlQuery(channel, "DESCRIBE Projects")
sqlQuery(channel, "INSERT INTO Projects(Project_ID,Contact_Name,Contact_Email,Citation,URL,Project_Name,Proprietary" VALUES('00211','National Ecological Observatory Network', '', 'National Ecological Observatory Network. 2019 and after. Provisional data downloaded from http://data.neonscience.org. Battelle, Boulder, CO, USA', 'https://www.neonscience.org/data','NEON',0)")
sqlQuery(channel, "INSERT INTO Projects(Project_ID,Contact_Name,Contact_Email,Citation,URL,Project_Name,Proprietary) VALUES('00211','National Ecological Observatory Network', '', 'National Ecological Observatory Network. 2019 and after. Provisional data downloaded from http://data.neonscience.org. Battelle, Boulder, CO, USA', 'https://www.neonscience.org/data','NEON',0)")
pl = sqlQuery(channel, "SELECT * FROM Projects")
View(pl)
dat = sqlQuery(channel, "SELECT * FROM Samples_test INNER JOIN Water_Isotope_Data ON Samples_test.Sample_ID = Water_Isotope_Data.Sample_ID")
View(dat)
dat1 = sqlQuery(channel, "SELECT * FROM Samples_test")
dat2 = sqlQuery(chanel, "SELECT * FROM Sites_test")
dat2 = sqlQuery(channel, "SELECT * FROM Sites_test")
View(dat2)
dat1 = sqlQuery(channel, "SELECT * FROM Samples_test INNER JOIN Sites_test ON Samples_test.Site_ID = Sites_test.Site.ID")
dat
dat``
dat1
dat1 = sqlQuery(channel, "SELECT * FROM Samples_test INNER JOIN Sites_test ON Samples_test.Site_ID = Sites_test.Site_ID")
View(dat1)
qrys = sqlQuery(channel, "SELECT MONTH(Time), COUNT(ID) FROM Tracking_log GROUP BY MONTH(Time)")
mean(qrys$`COUNT(ID)`)
View(qrys)
qrys = sqlQuery(channel, "SELECT YEAR_MONTH(Time), COUNT(ID) FROM Tracking_log GROUP BY MONTH(Time)")
qrys = sqlQuery(channel, "SELECT YEAR_MONTH(Time), COUNT(ID) FROM Tracking_log GROUP BY YEAR_MONTH(Time)")
qrys = sqlQuery(channel, "SELECT EXTRACT(YEAR_MONTH FROM Time), COUNT(ID) FROM Tracking_log GROUP BY EXTRACT(YEAR_MONTH FROM Time)")
mean(qrys$`COUNT(ID)`)
barplot(qrys$`COUNT(ID)`, xlab="Month", ylab="Count", col="red")
barplot(qrys$`COUNT(ID), names.arg=qrys$`EXTRACT(YEAR_MONTH FROM Time)`, xlab="Month", ylab="Count", col="red")
names(qrys) = c("Month", "Count")
barplot(qrys$Count, names.arg=qrys$Month, xlab="Month", ylab="Count", col="red")
mean(qrys$Count)
df.bar = barplot(qrys$Count, names.arg=qrys$Month, xlab="Month", ylab="Count", col="red")
df.bar = barplot(qrys$Count, names.arg=qrys$Month, xlab="Month", ylab="Count", col="red")
lines(df.bar, rep(mean(qrys$Count), nrow(df.bar)))
lines(df.bar, rep(mean(qrys$Count), nrow(df.bar)), lty=3)
df.bar = barplot(qrys$Count, names.arg=qrys$Month, xlab="Month", ylab="Count", col="red")
lines(df.bar, rep(mean(qrys$Count), nrow(df.bar)), lty=3)
qrys = sqlQuery(channel, "SELECT * FROM Tracking_log")
View(qrys)
write.csv(qrys, "C:/Users/gjbowen/Desktop/widb.csv")
library(RODBC)
channel = odbcConnect("WIDB")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE 'SPATIAL_19%'")
View(dat)
dat1 = sqlQuery(channel, "SELECT Samples.*, Sites.* FROM Samples INNER JOIN Sites ON Samples.Site_ID = Sites.Site_ID WHERE Samples.Sample_ID LIKE 'SPATIAL_19%'")
View(dat1)
dat2 = sqlQuery(channel, "SELECT Samples.*, Water_Isotope_Data.* FROM Samples INNER JOIN Water_Isotope_Data ON Samples.Sample_ID = Water_Isotope_Data.Sample_ID WHERE Samples.Sample_ID LIKE 'SPATIAL_19%'")
View(dat2)
library(mvtnorm)
library(MCMCpack)
#takes values of H and O isotope composition, SD of each, and covariance
iso = function(H,O,Hsd,Osd,HOc){
return(data.frame(H=H, O=O, Hsd=Hsd, Osd=Osd, HOc=HOc))
}
hyp = iso(-100, -11, 5, 0.5, 0.6)
obs = iso(-110, -12, 1, 0.1, 0.1)
val = rmvnorm(1000, c(obs$H, obs$O), matrix(c(obs$Hsd^2, rep(obs$HOc*obs$Hsd*obs$Osd, 2), obs$Osd^2),2,2))
View(val)
obs_prob = dmvnorm(c(hyp$H, hyp$O),c(obs$H, obs$O), sigma=matrix(c(obs$Hsd^2, rep(obs$HOc*obs$Hsd*obs$Osd,2), obs$Osd^2),2,2))
?dmvnorm
for(i in 1:1000){
obs_prob[i] = dmvnorm(c(hyp$H, hyp$O),c(obs$H, obs$O), sigma=matrix(c(obs$Hsd^2, rep(obs$HOc*obs$Hsd*obs$Osd,2), obs$Osd^2),2,2))
}
obs_prob[i] = dmvnorm(c(hyp$H, hyp$O),c(val[i,1], val[i,2]), sigma=matrix(c(obs$Hsd^2, rep(obs$HOc*obs$Hsd*obs$Osd,2), obs$Osd^2),2,2))
for(i in 1:1000){
obs_prob[i] = dmvnorm(c(hyp$H, hyp$O),c(val[i,1], val[i,2]), sigma=matrix(c(obs$Hsd^2, rep(obs$HOc*obs$Hsd*obs$Osd,2), obs$Osd^2),2,2))
}
##Load libraries
library(rjags)
library(R2jags)
library(xlsx)
##My local working directories
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/code/")
##Functions for plotting and data prep
source("helpers.R")
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/code/")
##Set up timeseries for MgCa_sw modeling
mgca_ts.min = 80
##Read in paleo-seawater MgCa data
d_mgca_sw = read.csv("mgca_sw.csv")
mgca_ages = d_mgca_sw$Age
mgca_ages = unique(mgca_ages)
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = find(d_mgca_sw$Age, mgca_ages)
?find
?match
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
mgca_ages = d_mgca_sw$Age
mgca_ages = unique(mgca_ages)
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Data to pass to BUGS model
dat = list(nmgca.ages = mgca_ages.len, mgca_ages = mgca_ages,
MgCa_sw.age.ind = mgca_sw_age.ind,
MgCa_sw = d_mgca_sw$MgCa, MgCa_sw.sd = d_mgca_sw$Sigma)
##Parameters to save
parameters = c("MgCa_sw_m", "MgCa_sw_m.pre", "MgCa_sw_m.eps.ac", "MgCa_sw_m.eps")
##Run it - <2 min for 250k samples
pt = proc.time()
n.iter = 500000
n.burnin = 20000
n.thin = floor((n.iter-n.burnin)/5000)
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
##Data to pass to BUGS model
dat = list(nmgca.ages = mgca_ages.len, mgca.ages = mgca_ages,
MgCa_sw.age.ind = mgca_sw_age.ind,
MgCa_sw = d_mgca_sw$MgCa, MgCa_sw.sd = d_mgca_sw$Sigma)
##Run it - <2 min for 250k samples
pt = proc.time()
n.iter = 500000
n.burnin = 20000
n.thin = floor((n.iter-n.burnin)/5000)
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
proc.time() - pt
save(post.mg, file = "post_mg.RData")
sl = post.mg$BUGSoutput$sims.list
su = post.mg$BUGSoutput$summary
sims = nrow(sl$MgCa_sw_m)
View(su)
plot(-10, 0, xlab="Age (Ma)", ylab ="Seawater Mg/Ca", xlim=c(0,80), ylim=c(0.8,6))
for(i in seq(1, sims, by = max(floor(sims / 2500),1))){
lines(mgca_ts.ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
}
lines(mgca_ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
for(i in seq(1, sims, by = max(floor(sims / 2500),1))){
lines(mgca_ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
}
lines(mgca_ts.ages, su[1:mgca_ts.len, 5], col="red")
lines(mgca_ages, su[1:mgca_ts.len, 5], col="red")
lines(mgca_ages, su[1:mgca_ages.len, 5], col="red")
lines(mgca_ages, su[1:mgca_ages.len, 3], col="red", lty=3)
lines(mgca_ages, su[1:mgca_ages.len, 7], col="red", lty=3)
points(d_mgca_sw$Age, d_mgca_sw$MgCa, pch=21)
mgca_ages = seq(0,80)
mgca_ages = rbind(mgca_ages, d_mgca_sw$Age)
mgca_ages = seq(0,80)
mgca_ages = c(mgca_ages, d_mgca_sw$Age)
mgca_ages = unique(mgca_ages)
mgca_ages = sort(mgca_ages)
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Data to pass to BUGS model
dat = list(nmgca.ages = mgca_ages.len, mgca.ages = mgca_ages,
MgCa_sw.age.ind = mgca_sw_age.ind,
MgCa_sw = d_mgca_sw$MgCa, MgCa_sw.sd = d_mgca_sw$Sigma)
pt = proc.time()
n.iter = 500000
n.burnin = 20000
n.thin = floor((n.iter-n.burnin)/5000)
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
proc.time() - pt
save(post.mg, file = "post_mg.RData")
sl = post.mg$BUGSoutput$sims.list
su = post.mg$BUGSoutput$summary
sims = nrow(sl$MgCa_sw_m)
View(su)
plot(-10, 0, xlab="Age (Ma)", ylab ="Seawater Mg/Ca", xlim=c(0,80), ylim=c(0.8,6))
for(i in seq(1, sims, by = max(floor(sims / 2500),1))){
lines(mgca_ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
}
lines(mgca_ages, su[1:mgca_ages.len, 5], col="red")
lines(mgca_ages, su[1:mgca_ages.len, 3], col="red", lty=3)
lines(mgca_ages, su[1:mgca_ages.len, 7], col="red", lty=3)
points(d_mgca_sw$Age, d_mgca_sw$MgCa, pch=21, bg="white")
mgca_ages = seq(0,80)
mgca_ages = c(mgca_ages, d_mgca_sw$Age)
mgca_ages = unique(mgca_ages)
mgca_ages = sort(mgca_ages, decreasing = TRUE)
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Data to pass to BUGS model
dat = list(nmgca.ages = mgca_ages.len, mgca.ages = mgca_ages,
MgCa_sw.age.ind = mgca_sw_age.ind,
MgCa_sw = d_mgca_sw$MgCa, MgCa_sw.sd = d_mgca_sw$Sigma)
pt = proc.time()
n.iter = 500000
n.burnin = 20000
n.thin = floor((n.iter-n.burnin)/5000)
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
proc.time() - pt
save(post.mg, file = "post_mg.RData")
sl = post.mg$BUGSoutput$sims.list
su = post.mg$BUGSoutput$summary
sims = nrow(sl$MgCa_sw_m)
View(su)
plot(-10, 0, xlab="Age (Ma)", ylab ="Seawater Mg/Ca", xlim=c(0,80), ylim=c(0.8,6))
for(i in seq(1, sims, by = max(floor(sims / 2500),1))){
lines(mgca_ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
}
pt = proc.time()
n.iter = 500000
n.burnin = 20000
n.thin = floor((n.iter-n.burnin)/5000)
post.mg = do.call(jags.parallel, list(model.file = "mg_model.R", parameters.to.save = parameters,
data = dat, inits = NULL, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin) )
proc.time() - pt
save(post.mg, file = "post_mg.RData")
sl = post.mg$BUGSoutput$sims.list
su = post.mg$BUGSoutput$summary
sims = nrow(sl$MgCa_sw_m)
View(su)
plot(-10, 0, xlab="Age (Ma)", ylab ="Seawater Mg/Ca", xlim=c(0,80), ylim=c(0.8,6))
for(i in seq(1, sims, by = max(floor(sims / 2500),1))){
lines(mgca_ages, sl$MgCa_sw_m[i,], col = rgb(0,0,0, 0.01))
}
View(su)
lines(mgca_ages, su[1:mgca_ages.len, 5], col="red")
lines(mgca_ages, su[1:mgca_ages.len, 3], col="red", lty=3)
lines(mgca_ages, su[1:mgca_ages.len, 7], col="red", lty=3)
points(d_mgca_sw$Age, d_mgca_sw$MgCa, pch=21, bg="white")
##Set up timeseries for d18O_sw and BWT modeling
ts.min = 18
ts.max = 0
ts.step = 0.05
ts.ages = seq(ts.min, ts.max, -ts.step)
##Prep the foram data, first read
d = read.csv("Lear_combined.csv")
##Now split out the d18O data and strip one outlier
d_o = d[!is.na(d$d18O),]
d_o = d_o[d_o$Sample.ID != "806B 47-5 38-43",]
#Add O data ages to age vector
ts.ages = c(ts.ages, d_o$Age.Ma)
##Now split out the MgCa data
d_mgca = d[!is.na(d$MgCa),]
#Add Mg/Ca data ages to age vector, condense, and sort
ts.ages = c(ts.ages, d_mgca$Age.Ma)
ts.ages = unique(ts.ages)
ts.ages = sort(ts.ages, decreasing = TRUE)
#Timeseries index for each d18O sample
ts.len = length(ts.ages)
o_age.ind = match(d_o$Age.Ma, ts.ages)
mgca_age.ind = match(d_mgca$Age.Ma, ts.ages)
##Read in paleo-seawater MgCa data
d_mgca_sw = read.csv("mgca_sw.csv")
##Set up timeseries for MgCa_sw modeling
mgca_ts.min = 80
mgca_ts.max = 0
mgca_ts.step = 1
mgca_ts.ages = seq(mgca_ts.min, mgca_ts.max, -mgca_ts.step)
mgca_ages = c(mgca_ages, d_mgca_sw$Age)
mgca_ages = unique(mgca_ages)
mgca_ages = sort(mgca_ages, decreasing = TRUE)
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Add age indicies for seawater MgCa TS to MgCa foram data
mgca_age.ind.sw = match(d_mgca$Age.Ma, mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Add age indicies for seawater MgCa TS to MgCa foram data
mgca_age.ind.sw = match(d_mgca$Age.Ma, mgca_ages)
mgca_ages = c(mgca_ages, d_mgca_sw$Age, d_mgca$Age.Ma)
mgca_ages = unique(mgca_ages)
mgca_ages = sort(mgca_ages, decreasing = TRUE)
##Age index for seawater MgCa proxy data and ts length
mgca_ages.len = length(mgca_ages)
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Add age indicies for seawater MgCa TS to MgCa foram data
mgca_age.ind.sw = match(d_mgca$Age.Ma, mgca_ages)
mgca_age.ind.all = matrix(c(mgca_age.ind, mgca_age.ind.sw), ncol = 2)
mgca_age.ind
mgca_age.ind.sw
mgca_sw_age.ind = match(d_mgca_sw$Age, mgca_ages)
##Add age indicies for seawater MgCa TS to MgCa foram data
mgca_age.ind.sw = match(d_mgca$Age.Ma, mgca_ages)
mgca_age.ind.all = matrix(c(mgca_age.ind, mgca_age.ind.sw), ncol = 2)
##Read in MgCa calibration dataset
d_mgca_calib = read.csv("O_mgca_calib.csv")
##Append all sample ages to ts age vector
mgca_ages = c(mgca_ages, d_mgca_sw$Age, d_mgca$Age.Ma, d_mgca_calib$Age)
mgca_ages = unique(mgca_ages)
mgca_ages = sort(mgca_ages, decreasing = TRUE)
##Age index for MgCa calibration samples
mgca_calib_age.ind = match(d_mgca_calib$Age, mgca_ages)
d_mgca_calib$Age
