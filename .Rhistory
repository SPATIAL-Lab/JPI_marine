MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.10, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
#plot it
plot(dat$dC, dat$dO, xlab = expression(paste("Carbonate ",delta^{13}, "C (\u2030)")),
ylab = expression(paste("Carbonate ",delta^{18}, "O (\u2030)")))
plot(T_seass, dat$dC)
T_seass = seq(5, 20, length.out = 20)
MAP = rnorm(nsynth, 600, 100)
MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.10, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
points(T_seass, dat$dC)
plot(T_seass, dat$dC)
lm(dat$dC ~ T_seass)
T_seass = seq(5, 20, length.out = 20)
MAP = rnorm(nsynth, 1200, 100)
MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.10, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
lm(dat$dC ~ T_seass)
case = 4
T_seass = seq(5, 20, length.out = 20)
MAP = rnorm(nsynth, 1200, 100)
MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.25, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
lm(dat$dC ~ T_seass)
MAP = rnorm(nsynth, 600, 100)
MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.25, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
lm(dat$dC ~ T_seass)
T_seass = seq(5, 20, length.out = 20)
MAP = rnorm(nsynth, 1000, 100)
MAT = rnorm(nsynth, 20, 1)
P_seas = rnorm(nsynth, 0.25, 0.02)
pCO2 = rnorm(nsynth, 750, 25)
dat = sm_forward()
lm(dat$dC ~ T_seass)
library(RODBC)
channel = odbcConnect("WIDB")
install.packages("RODBC")
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SHOW TABLES")
sqlQuery(channel, "DESCRIBE Projects")
sqlQuery(channel, "SELECT * FROM Projects WHERE Project_ID = '00166'")
sqlQuery(channel, "UPDATE Projects SET Proprietary = 0 WHERE Project_ID = '00166'")
sqlQuery(channel, "SELECT * FROM Projects WHERE Project_ID = '00166'")
fname = "C:/Users/u0133977/Dropbox/Bowen_Lab/Data_reports/NEON/Shipping/manifest_for_D1120180501164402947.csv"
library(RODBC) #loads required library
library(xlsx) #loads required library
#create channel with filepath to the database
channel = odbcConnect("WIDB")
#read in relevant sheet from NEON spreadsheet
samples <- read.csv(fname, stringsAsFactors = FALSE)
#subset df to include only rows with sample IDs (drops rows with no data)
samples <- samples[!is.na(samples$sampleID),]
#get number of samples
ns = nrow(samples)
#format the shipped date field as a date (required to enter into database)
if(class(samples$dateShipped)=="character"){
samples$dateShipped <- as.Date(samples$dateShipped,"%m/%d/%Y")
}
#format the collection date as a date
if(class(samples$collectdate)=="character"){
samples$collectdate <- as.Date(samples$collectdate,"%Y-%m-%d")
}
#add received date to samples
today = as.Date(date(), "%a %b %d %H:%M:%S %Y")
samples$shipmentReceivedDate = rep(today, ns)
#get and add analyst name and job number
rbname = readline("Your full name: ")
jnum = readline("Job number: ")
#add columns for additional info
trash = rep("N", ns)
samples$sampleReceived = trash
trash = rep("", ns)
samples$acceptedForAnalysis = trash
samples$sampleCondition = trash
samples$unknownSamples = trash
samples$remarks = trash
#set some terms lists and error messages
condlist = c("damaged", "sample incomplete", "handling error", "other")
ynerr = "Bad value, only Y and N allowed\n"
#read in relevant sheet from NEON spreadsheet
samples <- read.csv(fname, stringsAsFactors = FALSE)
#subset df to include only rows with sample IDs (drops rows with no data)
samples <- samples[!is.na(samples$sampleID),]
#get number of samples
ns = nrow(samples)
#format the shipped date field as a date (required to enter into database)
if(class(samples$dateShipped)=="character"){
samples$dateShipped <- as.Date(samples$dateShipped,"%m/%d/%Y")
}
#read in relevant sheet from NEON spreadsheet
samples <- read.csv(fname, stringsAsFactors = FALSE)
#subset df to include only rows with sample IDs (drops rows with no data)
samples <- samples[!is.na(samples$sampleID),]
#get number of samples
ns = nrow(samples)
?grep
yst = grep("201", samples$dateShipped[1])
yst
yst = gregexpr("201", samples$dateShipped[1])
gregexpr("201", samples$dateShipped[1])
yst[1]
yst[1][1]
yst[1,1]
yst[[1]]
yst[[1]][1]
switch
switch?
yst = gregexpr("201", samples$dateShipped[1])
if yst<2{ dform = "%Y-%m-%d" } else {
dform = "%m/%d/%Y"
}
if(yst<2){ dform = "%Y-%m-%d" } else {
dform = "%m/%d/%Y"
}
samples$dateShipped <- as.Date(samples$dateShipped,"%m/%d/%Y")
#read in relevant sheet from NEON spreadsheet
samples <- read.csv(fname, stringsAsFactors = FALSE)
#subset df to include only rows with sample IDs (drops rows with no data)
samples <- samples[!is.na(samples$sampleID),]
#get number of samples
ns = nrow(samples)
#format the shipped date field as a date (required to enter into database)
if(class(samples$dateShipped)=="character"){
yst = gregexpr("201", samples$dateShipped[1])
if(yst<2){ dform = "%Y-%m-%d" } else {
dform = "%m/%d/%Y"
}
samples$dateShipped <- as.Date(samples$dateShipped, dform)
}
#format the collection date as a date
if(class(samples$collectdate)=="character"){
yst = gregexpr("201", samples$dateShipped[1])
if(yst<2){ dform = "%Y-%m-%d" } else {
dform = "%m/%d/%Y"
}
samples$collectdate <- as.Date(samples$collectdate, dform)
}
#add received date to samples
today = as.Date(date(), "%a %b %d %H:%M:%S %Y")
samples$shipmentReceivedDate = rep(today, ns)
#get and add analyst name and job number
rbname = readline("Your full name: ")
samples$receivedBy = rep(rbname, ns)
jnum = readline("Job number: ")
samples$jobNumber = rep(jnum, ns)
#add columns for additional info
trash = rep("N", ns)
samples$sampleReceived = trash
trash = rep("", ns)
samples$acceptedForAnalysis = trash
samples$sampleCondition = trash
samples$unknownSamples = trash
samples$remarks = trash
#set some terms lists and error messages
condlist = c("damaged", "sample incomplete", "handling error", "other")
ynerr = "Bad value, only Y and N allowed\n"
#Input any unknown sample IDs - need confirmation on this
tok = "a"
i=1
cat("\n")
while(tok != ""){
tok = readline("Enter Sample IDs for unknown samples, return for done: ")
if(tok != "a" && tok != ""){
samples[ns+i,] = NA
samples$shipmentID[ns+i] = samples$shipmentID[ns]
samples$sampleClass[ns+i] = samples$sampleClass[ns]
samples$sampleID[ns+i] = tok
samples$unknownSamples[ns+i] = tok
i = i+1
}
}
View(samples)
for(i in 1:ncol(samples)){for(j in 1:nrow(samples)){if(samples[j,i]==NA)samples[j,i]=""}}
for(i in 1:ncol(samples)){for(j in 1:nrow(samples)){if(samples[j,i]==NA)samples[j,i]=NULL}}
for(i in 1:ncol(samples)){for(j in 1:nrow(samples)){if(samples[j,i]==NA){samples[j,i]=NULL}}}
for(i in 1:ncol(samples)){for(j in 1:nrow(samples)){if(samples[j,i]=="NA"){samples[j,i]=NULL}}}
j = 13
i = 1
if(samples[j,i]=="NA"){samples[j,i]=NULL}
if(is.na(samples[j,i])){samples[j,i]=NULL}
if(is.na(samples[j,i])){samples[j,i]=""}
for(i in 1:ncol(samples)){
for(j in 1:nrow(samples)){
if(is.na(samples[j,i])){samples[j,i]=""}
}
}
#Write receipt form
receipt = data.frame("shipmentID" = samples$shipmentID,
"shipmentReceivedDate" = samples$shipmentReceivedDate,
"receivedBy" = samples$receivedBy,
"sampleID" = samples$sampleID,
"sampleCode"=rep("", nrow(samples)),
"sampleClass" = samples$sampleClass,
"sampleReceived" = samples$sampleReceived,
"acceptedForAnalysis" = samples$acceptedForAnalysis,
"sampleCondition" = samples$sampleCondition,
"unknownSamples" = samples$unknownSamples,
"remarks" = samples$remarks)
fname = paste0("Bowen_Lab/Data_reports/NEON/Shipping/receipt_form_", receipt$shipmentID[1], ".csv")
write.csv(receipt, fname, row.names = FALSE, na = "")
sqlQuery(channel, "DESCRIBE NEON_shipping")
sqlQuery(channel, "DESCRIBE NEON_shipping")
sqlQuery(channel, "DESCRIBE NEON_shipping")
#create channel with filepath to the database
channel = odbcConnect("WIDB")
sqlQuery(channel, "DESCRIBE NEON_shipping")
install.packages("raster")
install.packages("sp")
install.packages("rgdal")
install.packages("ggplot2")
install.packages("devtools")
devtools::install_github("SPATIAL-Lab/isorig", force =T)# install isOrigin package from Github
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "COUNT d2H FROM Water_Isotope_Data")
sqlQuery(channel, "SELECT COUNT(d2H) FROM Water_Isotope_Data")
sqlQuery(channel, "SELECT COUNT(d18O) FROM Water_Isotope_Data")
sqlQuery(channel, "SELECT COUNT(d18O) FROM Water_Isotope_Data WHERE WI_Analysis_Ignore = 0")
sqlQuery(channel, "SELECT COUNT(Sample_ID) FROM Samples")
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT COUNT(Sample_ID) FROM Samples")
library(devtools)
devtools::install_github("SPATIAL-Lab/isorig", force=T)
data("naMap")
library(isOrigin)
data("naMap")
data("d2h_world")
d = subOrigData(taxon = c("Homo sapiens"), mask = naMap)
sumary(d)
summary(d)
r = calRaster(dd, d2h_world, naMap)
r = calRaster(d, d2h_world, naMap)
d = d[d$d2H < -75]
d = d[d$d2H < -75,]
r = calRaster(d, d2h_world, naMap)
id = c("A", "B", "C", "D")
d2H = c(-110, -105, -100, -120)
un = data.frame(id,d2H)
asn = pdRaster(r$isoscape.rescale,unknown=un,mask=naMap)
p1 <- c(-100,45,-100,50,-110,50,-110,45,-100,45)
p1 <- matrix(p1, 5,2, byrow = T)
p1 <- Polygon(p1)
p1 <- Polygons(list(p1), "p1")
p2 <- c(-100,40,-100,45,-110,45,-110,40,-100,40)
p2 <- matrix(p2, 5,2, byrow = T)
p2 <- Polygon(p2)
p2 <- Polygons(list(p2), "p2")
p12 <- SpatialPolygons(list(p1,p2),1:2)
pp1 <- c(-100,45)
pp2 <- c(-100,60)
pp12 <- as.data.frame(rbind(pp1,pp2))
fname = "C:/Users/u0133977/Dropbox/Bowen_Lab/Sample_metadata/test"
library(readxl)
library(RODBC)
channel = odbcConnect("WIDB")
Sys.setenv(TZ= "GMT")
if(fname == ""){
projectFile = "Projects.csv"
siteFile = "Sites.csv"
samplesFile = "Samples.csv"
csvImport = 1
} else {
csvImport = 0
}
#####Figure out what needs to be imported
SitesYN = T
SamplesYN = T
ProjectsYN = T
AnalysisYN = T
ClimateYN = T
tmpdat = read_excel(fname, sheet="Samples", col_names = TRUE,
col_types = c("text", "text", "text", "text", "guess",
"numeric", "guess", "numeric", "numeric",
"text", "text", "numeric", "text",
"numeric", "text", "text"))
fname = "C:/Users/u0133977/Dropbox/Bowen_Lab/Sample_metadata/test/test.xlsx"
tmpdat = read_excel(fname, sheet="Samples", col_names = TRUE,
col_types = c("text", "text", "text", "text", "guess",
"numeric", "guess", "numeric", "numeric",
"text", "text", "numeric", "text",
"numeric", "text", "text"))
oddsRatio(asn, p12)
oddsRatio(asn, pp12)
qtlRaster(asn, threshold = 0.7, thresholdType = 1)
qtlRaster(asn, threshold = 0.7, thresholdType = 2)
jointP(asn)
unionP(asn)
install.packages(c("cli", "coda", "digest", "doParallel", "dplyr", "e1071", "expm", "GGally", "glue", "iterators", "maptools", "mcmcplots", "mime", "munsell", "mvtnorm", "openssl", "pillar", "pkgconfig", "progress", "purrr", "R6", "rbacon", "Rcpp", "rjags", "rlang", "rstudioapi", "scales", "spData", "stringi", "stringr", "tidyr", "tidyselect", "utf8"))
install.packages(c("cli", "coda", "digest", "doParallel", "dplyr", "e1071", "expm", "GGally", "glue", "iterators", "maptools", "mcmcplots", "mime", "munsell", "mvtnorm", "openssl", "pillar", "pkgconfig", "progress", "purrr", "R6", "rbacon", "Rcpp", "rjags", "rlang", "rstudioapi", "scales", "spData", "stringi", "stringr", "tidyr", "tidyselect", "utf8"))
install.packages(c("cli", "coda", "digest", "doParallel", "dplyr", "e1071", "expm", "GGally", "glue", "iterators", "maptools", "mcmcplots", "mime", "munsell", "mvtnorm", "openssl", "pillar", "pkgconfig", "progress", "purrr", "R6", "rbacon", "Rcpp", "rjags", "rlang", "rstudioapi", "scales", "spData", "stringi", "stringr", "tidyr", "tidyselect", "utf8"))
library(RODBC)
channel = odbcConnect("WIDB")
d=sqlQuery(channel, "SELECT * FROM Samples WHERE Project_ID = '00099'")
dd = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%GJBMISC18%'")
View(dd)
View(d)
load("post_lear.RData")
library(R2OpenBUGS)
library(coda)
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/gjbowen/Dropbox/HypoMirror/JPI_marine/")
citation()
library(RODBC)
odc = odbcConnect("ITCE")
applied = sqlQuery(odc, "SELECT people.*,  application.*
FROM application INNER JOIN people ON
people.Person_ID =  application.Person_ID
WHERE application.CYear = '2019'")
View(applied)
library(RODBC)
channel = odbcConnect("WIDB")
bad = sqlQuery(channel, "SELECT Sample_ID FROM Water_Isotope_Data WHERE Samples_ID LIKE '%ONULL%")
sqlQuery(channel, "SHOW TABLES")
bad
bad = sqlQuery(channel, "SELECT Sample_ID FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULL%")
bad = sqlQuery(channel, "SELECT Sample_ID FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULL%'")
bad = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULL%'")
View(bad)
bad = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULLQ%'")
sqlQuery(channel, "DESCRIBE NEON_shipping")
bad_r = sqlQuery(channel, "SELECT * FROM NEON_shipping WHERE sampleID LIKE '%ONULLQ%'")
bad_s = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULLQ%'")
?gsub
bad_s$newID = gsub("NULL", "NA", bad_s$Sample_ID)
bad_r$newID = gsub("NULL", "NA", bad_r$sampleID)
View(bad_r)
i=1
qs = paste0("UPDATE Water_Isotope_Data SET Sample_ID = '", bad_s$newID[i], "' WHERE Sample_ID = '", bad_s$Sample_ID, "'")
qs
qs = paste0("UPDATE Water_Isotope_Data SET Sample_ID = '", bad_s$newID[i], "' WHERE Sample_ID = '", bad_s$Sample_ID[i], "'")
qs
for(i in 1:nrow(bad_s)){
qs = paste0("UPDATE Water_Isotope_Data SET Sample_ID = '", bad_s$newID[i], "' WHERE Sample_ID = '", bad_s$Sample_ID[i], "'")
sqlQuery(channel, qs)
}
nrow(bad_s)
for(i in 1:nrow(bad_r)){
qs = paste0("UPDATE NEON_shipping SET sampleID = '", bad_r$newID[i], "' WHERE sampleID = '", bad_r$sampleID[i], "'")
sqlQuery(channel, qs)
}
bad_s = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULLQ%'")
bad_r = sqlQuery(channel, "SELECT * FROM NEON_shipping WHERE sampleID LIKE '%ONULLQ%'")
bad_s
channel = odbcConnect("WIDB")
bad_s = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%ONULLQ%'")
bad_r = sqlQuery(channel, "SELECT * FROM NEON_shipping WHERE sampleID LIKE '%ONULLQ%'")
bad_s$newID = gsub("NULL", "NA", bad_s$Sample_ID)
bad_r$newID = gsub("NULL", "NA", bad_r$sampleID)
for(i in 1:nrow(bad_r)){
qs = paste0("UPDATE NEON_shipping SET sampleID = '", bad_r$newID[i], "' WHERE sampleID = '", bad_r$sampleID[i], "'")
sqlQuery(channel, qs)
}
bad_r$newID = gsub("NULL", "NA", bad_r$sampleID)
bad_r = sqlQuery(channel, "SELECT * FROM NEON_shipping WHERE sampleID LIKE '%ONULLQ%'")
library(RODBC)
channel = odbcConnect("WIDB")
sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID = '16-379_CUPE.ss.20161206.H2O.1'")
sqlQuery(channel, "SELECT * FROM Sites WHERE Site_ID = 'CUPE.AOS.S2'")
library(RODBC)
channel = odbcConnect("WIDB")
types = sqlQuery(channel, "SELECT Type, COUNT(Type) FROM Samples GROUP BY Type")
types = types[order(types$`COUNT(Type)`, decreasing = TRUE),]
bigtypes = types[1:7,]
bigtypes$Type = as.character(bigtypes$Type)
others = c("Other", sum(types$`COUNT(Type)`[8:nrow(types)]))
bigtypes = rbind(bigtypes, others)
bigtypes$`COUNT(Type)` = as.numeric(bigtypes$`COUNT(Type)`)
pal = rev(colorspace::sequential_hcl(8))
bigtypes = bigtypes[order(bigtypes$`COUNT(Type)`),]
pie(bigtypes$`COUNT(Type)`, labels = paste0(bigtypes$Type, " (", bigtypes$`COUNT(Type)`, ")"), col=pal)
people = sqlQuery(channel, "SELECT Projects.Contact_Name, COUNT(Samples.Sample_ID)
FROM Projects INNER JOIN Samples
ON Projects.Project_ID = Samples.Project_ID
GROUP BY Projects.Contact_Name")
people = people[order(people$`COUNT(Samples.Sample_ID)`, decreasing = TRUE),]
bigpeople = people[1:10,]
bigpeople$Contact_Name = as.character(bigpeople$Contact_Name)
others = c("Other", sum(people$`COUNT(Samples.Sample_ID)`[11:nrow(people)]))
bigpeople = rbind(bigpeople, others)
bigpeople$`COUNT(Samples.Sample_ID)` = as.numeric(bigpeople$`COUNT(Samples.Sample_ID)`)
bigpeople = bigpeople[order(bigpeople$`COUNT(Samples.Sample_ID)`),]
pal = rev(colorspace::sequential_hcl(11))
pie(bigpeople$`COUNT(Samples.Sample_ID)`, labels = paste0(bigpeople$Contact_Name, " (",
bigpeople$`COUNT(Samples.Sample_ID)`, ")")
, col = pal)
qrys = sqlQuery(channel, "SELECT EXTRACT(YEAR_MONTH FROM Time), COUNT(ID) FROM Tracking_log GROUP BY EXTRACT(YEAR_MONTH FROM Time)")
names(qrys) = c("Month", "Count")
df.bar = barplot(qrys$Count, names.arg=qrys$Month, xlab="Month", ylab="Count", col="red")
lines(df.bar, rep(mean(qrys$Count), nrow(df.bar)), lty=3)
library(RODBC)
channel = odbcConnect("WIDB")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%PRPO.w3%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%WDP.OSBS.20170920.1123%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%OSBS.20170920.1123%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%OSBS.20170920%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%PRPO.w3%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%20170920%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%UNDE.20190410.1105%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%UNDE%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%OSBS%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%WDP.CLBJ.20190116.1512%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%WDP.CLBJ%'")
dat = sqlQuery(channel, "SELECT * FROM Samples WHERE Sample_ID LIKE '%WDP.CLBJ.20190116.1512.ISO.TEST'")
dat = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%WDP.CLBJ.20190116.1512.ISO.TEST'")
dat = sqlQuery(channel, "SELECT * FROM Water_Isotope_Data WHERE Sample_ID LIKE '%OSBS.20170920%'")
##Load libraries
library(rjags)
library(R2jags)
library(xlsx)
setwd("C:/Users/u0133977/Dropbox/HypoMirror/JPI_marine/code/")
##Functions for plotting and data prep
source("helpers.R")
d = prep.birn()
##Parameters to be saved
parameters = c("d18O_sw", "BWT", "BWT.eps.ac", "BWT.pre", "d18O_sw.eps.ac", "d18O_sw.pre",
"a", "MgCa_calib.pre", "b", "d18O_calib.pre")
##Data to pass to the model
dat = list(nages = d$ts.len, ages = d$ts.ages,
MgCa_calib.bwt.m = d$d_mgca_calib$BWT, MgCa_calib.bwt.sd = d$d_mgca_calib$BWT_sd, MgCa_calib = d$d_mgca_calib$MgCa,
d18O_calib.bwt.m = d$d_d18O_calib$BWT, d18O_calib.bwt.sd = d$d_d18O_calib$BWT_sd, d18O_calib = d$d_d18O_calib$d18O_f.sw,
MgCa_sw.neo = d$mgca_sw_neo,
MgCa.age.ind = d$mgca_age.ind, MgCa = d$d_mgca$MgCa,
d18O.age.ind = d$o_age.ind, d18O = d$d_o$d18O)
##Run the inversion - 50 min for 500k samples
#Start time
t1 = proc.time()
#Some parameters for the sampler
set.seed(t1[3])
n.iter = 50000
n.burnin = 10000
n.thin = floor(n.iter-n.burnin)/5000
#Run it
post.birn = do.call(jags.parallel, list(model.file = "split_temporal_birn.R", parameters.to.save = parameters,
data = dat, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin))
#Time taken
proc.time() - t1
##Save posterior samples + info
save(post.birn, file = "post_birn.RData")
49000/60
816/60
t1 = proc.time()
#Some parameters for the sampler
set.seed(t1[3])
n.iter = 500000
n.burnin = 10000
n.thin = floor(n.iter-n.burnin)/5000
#Run it
post.birn = do.call(jags.parallel, list(model.file = "split_temporal_birn.R", parameters.to.save = parameters,
data = dat, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin))
#Time taken
proc.time() - t1
##Save posterior samples + info
save(post.birn, file = "post_birn.RData")
#Some parameters for the sampler
set.seed(t1[3])
n.iter = 500000
n.burnin = 10000
n.thin = floor(n.iter-n.burnin)/5000
#Start time
t1 = proc.time()
#Run it
post.birn = do.call(jags.parallel, list(model.file = "split_temporal_birn.R", parameters.to.save = parameters,
data = dat, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin))
#Time taken
proc.time() - t1
##Save posterior samples + info
save(post.birn, file = "post_birn.RData")
##Prepare the site U1385 data
d = prep.birn()
##Parameters to be saved
parameters = c("d18O_sw", "BWT", "BWT.eps.ac", "BWT.pre", "d18O_sw.eps.ac", "d18O_sw.pre",
"a", "MgCa_calib.pre", "b", "d18O_calib.pre")
##Data to pass to the model
dat = list(nages = d$ts.len, ages = d$ts.ages,
MgCa_calib.bwt.m = d$d_mgca_calib$BWT, MgCa_calib.bwt.sd = d$d_mgca_calib$BWT_sd, MgCa_calib = d$d_mgca_calib$MgCa,
d18O_calib.bwt.m = d$d_d18O_calib$BWT, d18O_calib.bwt.sd = d$d_d18O_calib$BWT_sd, d18O_calib = d$d_d18O_calib$d18O_f.sw,
MgCa_sw.neo = d$mgca_sw_neo,
MgCa.age.ind = d$mgca_age.ind, MgCa = d$d_mgca$MgCa,
d18O.age.ind = d$o_age.ind, d18O = d$d_o$d18O)
##Run the inversion - 50 min for 500k samples
#Some parameters for the sampler
set.seed(t1[3])
n.iter = 500000
n.burnin = 10000
n.thin = floor(n.iter-n.burnin)/5000
#Start time
t1 = proc.time()
#Run it
post.birn = do.call(jags.parallel, list(model.file = "split_temporal_birn.R", parameters.to.save = parameters,
data = dat, n.chains=3, n.iter = n.iter,
n.burnin = n.burnin, n.thin = n.thin))
#Time taken
proc.time() - t1
##Save posterior samples + info
save(post.birn, file = "post_birn.RData")
